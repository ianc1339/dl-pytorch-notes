{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cc3dd9-7641-428b-9a28-36ec3a0c47af",
   "metadata": {},
   "source": [
    "# Chapter 3 - It starts with a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683f9dd-0d11-4095-a053-eca67ed80516",
   "metadata": {},
   "source": [
    "Tensors are the fundamental data structure in PyTorch. They are multidimensional arrays that stores a collection of numbers. These numbers are accessible individually using an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9244ec1-88eb-4e15-87fa-da7489b73199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3) # Creates a one-dimensional tensor of size 3 filled with 1s.\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ac10da-0dd3-417a-81cb-6717e9284c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1] # Accesses second element of tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ddc6529-84fe-4ec8-88ab-4ae4cdedd027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1]) # Returns second element of tensor as float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d26e29-d552-4a16-a1b6-fafd7146ec9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0 # Changes third element of tensor to 2.\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c48055-2d9e-4ae4-bfa9-7bb07ecd2085",
   "metadata": {},
   "source": [
    "## 1 - 2D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d7a06-b99d-4d3a-84e6-e057de7bcecd",
   "metadata": {},
   "source": [
    "To store multiple coordinates in a tensor, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423ce1ec-7970-40c1-8c1b-146191af6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa468b-7e7d-45e8-8f54-8a2183ad79bc",
   "metadata": {},
   "source": [
    "Alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4d7fb1-62bb-4823-a848-cee5bbe1e0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0]) # Creates tensor by passing list to constructor.\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96b987-d66a-4d7c-9c0a-cdefadebd7d0",
   "metadata": {},
   "source": [
    "To get the coordinates of the first point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cc8bc0-c68c-411f-8ea0-369e97ae009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45e863-972a-4872-87ed-33b59ecf949c",
   "metadata": {},
   "source": [
    "However, this is impractical. It is more efficient to use a 2D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca14351-ab73-4f86-82de-f673c6da9796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]]) # Creates 2D tensor.\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef6a0c7-bfd3-4e2b-92c2-e1577520a3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape # Returns shape of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2358cce1-d1a3-46ca-96df-e6c0396926e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1] # Returns y-coordinate of first point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1457ebe-bbc3-4244-95b0-4c82d548ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0] # Returns coordinate of first point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f385a73-20c7-4491-be7a-8eb268e55366",
   "metadata": {},
   "source": [
    "Tensors can be range indexed just like Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214b2207-e4a3-41a2-978e-2f973a59c207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ee3efc-c641-40c4-a88a-9616b4f11e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64496a30-4080-42d1-a233-3a87675c6966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1669fffc-de2f-4f39-bf12-45e237552ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[None] # Adds a dimension of size 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d489faa-0588-4242-ab9c-e5801e7eb4ed",
   "metadata": {},
   "source": [
    "## 2 - Named tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d701657e-1c92-445c-896b-c9b124a9cd74",
   "metadata": {},
   "source": [
    "(Note: named tensors are still an experimental feature at the time of writing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c71bb-93e4-4bd3-98ee-3b29db97ecf6",
   "metadata": {},
   "source": [
    "The dimensions of tensors usually index things like pixel locations or color channels. When the tensor gets transformed, keeping track of which dimension contains what data can be error-prone. The `tensor` function takes a `names` argument (a sequence of strings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3870512-5172-44da-8bc5-25465daa4bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7999/2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1463.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4b6da-c4a2-49e3-9cfa-668fab5b01ad",
   "metadata": {},
   "source": [
    "If a tensor already exists and want to add names to it, we can use the `refine_names` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b8ae7ff-d17c-4de7-b6f4-3051c9b30bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5)\n",
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print('img named:', img_named.shape, img_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e254cf-f614-46f3-9e2d-43d66be1d9d6",
   "metadata": {},
   "source": [
    "The `align_as` method returns a tensor with the missing dimensions added and existing ones permuted to the right order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6625ceb3-d02d-43ff-b064-43d01418ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights named: torch.Size([3]) ('channels',)\n",
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "weights aligned: torch.Size([3, 1, 1]) ('channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "print('weights named:', weights_named.shape, weights_named.names)\n",
    "print('img named:', img_named.shape, img_named.names)\n",
    "\n",
    "weights_aligned = weights_named.align_as(img_named)\n",
    "print('weights aligned:', weights_aligned.shape, weights_aligned.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429cfbac-c637-4c2c-a709-34390a958dcc",
   "metadata": {},
   "source": [
    "Functions like `sum`, which accept a dimension argument, can also take named dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12ae8ce5-4b3d-454f-b60c-7d5d2d4f37cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named*weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c4171-99cd-4893-a15f-5f73ecee213b",
   "metadata": {},
   "source": [
    "Combining tensors that have dimensions with different names gives an error. For example, if we run the following line of code:\n",
    "\n",
    "```\n",
    "gray_named = (img_named[..., :3]*weights_named).sum('channels')\n",
    "```\n",
    "\n",
    "it would give an error since:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10b483c1-0ff3-40c3-a1e5-341c09b34441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('channels', 'rows', 'columns')\n",
      "('channels',)\n"
     ]
    }
   ],
   "source": [
    "print(img_named[..., :3].names)\n",
    "print(weights_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12e30f-b8b3-4350-afaa-0685c5ead355",
   "metadata": {},
   "source": [
    "If we want to make a named tensor unnamed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eae3f62-a99c-4253-b3fa-a5874d4a8fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a207e610-d58f-46a6-a219-43dfe0473753",
   "metadata": {},
   "source": [
    "## 3 - More on tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66ddbd-d14d-4134-8926-05cf968e7d04",
   "metadata": {},
   "source": [
    "The `dtype` argument for tensors specifies the data type of elements that will be contained in the tensor. The following are the possible values for the `dtype` argument:\n",
    "\n",
    "- `torch.float32` or `torch.float`\n",
    "- `torch.float64` or `torch.double`\n",
    "- `torch.float16` or `torch.half`\n",
    "- `torch.int8`\n",
    "- `torch.uint8`\n",
    "- `torch.int16` or `torch.short`\n",
    "- `torch.int32` or `torch.int`\n",
    "- `torch.int64` or `torch.long`\n",
    "- `torch.bool`\n",
    "\n",
    "The `dtype` argument can be specified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc9bd5c-1b27-453e-be21-be018860bbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
    "\n",
    "short_points.dtype # Returns the data type of the tensor short_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f84c42-15ee-47d5-aeb6-dc06f9ca7407",
   "metadata": {},
   "source": [
    "The output of a tensor creation function can also be casted to the desired data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a204d7f0-ba24-435a-97c8-180a72cfcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48646f1-78b4-4479-ba82-a14bfabc7eb1",
   "metadata": {},
   "source": [
    "Alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "815cd84f-89bf-41a9-8d16-00797cef509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(10, 2).to(dtype=torch.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe15493-414f-45ab-ab6e-efe49c118129",
   "metadata": {},
   "source": [
    "When mixing input types, the inputs are converted to the larger data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d31e136-b737-4a55-bdb0-2d159fef9d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_64 = torch.rand(5, dtype=torch.double)\n",
    "points_short = points_64.to(torch.short)\n",
    "points_64 * points_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3cfef-94d2-40a9-8764-c8b6c25d40a6",
   "metadata": {},
   "source": [
    "## 4 - Tensors as scenic view of storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1abad-2bb4-4631-8e5d-00a8b99f3c5e",
   "metadata": {},
   "source": [
    "Values in tensors are allocated in contiguous chunks of memory managed by `tensor.Storage` instances. The following shows indexing into storage works with 2D tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "471fdeb1-77b1-4df6-a795-ca41a18e1b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage() # Accesses the storage of the points tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653c07f-1964-4ab0-86d5-4fa43d958685",
   "metadata": {},
   "source": [
    "The storages can be indexed manually as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d5311e3-2cfb-401f-b430-deee72b66958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a3eeb-8ee4-4f20-9af7-a5d8225640dc",
   "metadata": {},
   "source": [
    "In addition, changing the value of a storage leads to changing the content of its referring tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b5961d-6734-4a3a-b664-1c69127d2415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()[0] = 2.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d98bb-4e02-44a2-82d8-0ba28a5ce4bb",
   "metadata": {},
   "source": [
    "Some methods of the `Tensor` object operates *in place* by modifying the input instead of creating and returning a new tensor object. They are recognizable by the trailing underscore in their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a207124-17cf-4a4f-93a2-0f133a694081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bccae9-0702-4895-a143-012c5a641f8b",
   "metadata": {},
   "source": [
    "## 5 - Tensor metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec3db6-f2ce-4435-9e98-a59680eac6cf",
   "metadata": {},
   "source": [
    "Tensors rely on a few pieces of information in order to index into a storage: size, offset and stride.\n",
    "- Size: Indicates how many elements there are in each dimension\n",
    "- Offset: Index in the storage referring to the first element of the tensor\n",
    "- Stride: Number of elements to skip in order to obtain the next element in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88cab966-fdda-4afc-8524-829fe448f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([3, 2])\n",
      "Offset: 0\n",
      "Stride: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print('Size:', points.size()) # This contains the same information as points.shape.\n",
    "print('Offset:', points.storage_offset())\n",
    "print('Stride:', points.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4ee8d-734d-4406-bd59-da441d85f157",
   "metadata": {},
   "source": [
    "This relationship between tensors and storages mean that operations like tranpose and extracting subtensors are inexpensive since memory reallocation is not required. Instead, a new tensor object is allocated with different values for size, offset and stride.\n",
    "\n",
    "The following extracts a subtensor from the `points` tensor and displays the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e0877d9-5572-4d51-a4b2-09ddc1d955c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2])\n",
      "Offset: 2\n",
      "Stride: (1,)\n"
     ]
    }
   ],
   "source": [
    "second_point = points[1]\n",
    "print('Size:', second_point.size())\n",
    "print('Offset:', second_point.storage_offset())\n",
    "print('Stride:', second_point.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833710a-fa5c-4f1e-990f-cc40e681fa55",
   "metadata": {},
   "source": [
    "`points` and `second_point` share the same storage object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64d32b59-0fd7-41fe-98f4-6469a4bff5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage().data_ptr() == second_point.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58365f68-0bf4-4529-bbe8-90aba7e676fe",
   "metadata": {},
   "source": [
    "Hence, changing the subtensor also affects the original tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bc8a590-12d4-4b7a-9395-1b84fb9f39e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160f74b-4b4b-4fbb-8f47-4d3a5a6cae3c",
   "metadata": {},
   "source": [
    "In cases where this is not desirable, we can clone the subtensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd223af2-6330-484b-bf24-b0462ba68d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aab31e-f357-4496-9e3a-06788b57de14",
   "metadata": {},
   "source": [
    "Note that `second_point` does not share its storage object with `points` anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32c7fb62-b4c1-4bb7-b62c-416a1c42f770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage().data_ptr() == points.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21134a2b-1429-4653-b102-d993697ed41e",
   "metadata": {},
   "source": [
    "The same idea applies for transposing tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7da36c7-ef97-48e6-8bcd-b8e4b33080a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cdd1a-9f4a-40b6-a4d5-ba49d42f7884",
   "metadata": {},
   "source": [
    "`points` and `points_t` share the same storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2218e0c-d6ac-4c00-b836-9a8b69c321f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage().data_ptr() == points_t.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf381042-6af0-4692-97e1-2c7d3c184b0e",
   "metadata": {},
   "source": [
    "The only difference between the two tensors is their shape and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41424bcb-83af-4810-bb4a-bf034add8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(points.stride())\n",
    "print(points_t.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c74ed8-b87e-4713-a6f6-abfddcd1c24c",
   "metadata": {},
   "source": [
    "Also, while `points` is a contiguous tensor, `points_t` is not. A contiguous tensor is one such that the values are laid out in the storage by starting from the right most dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a75eac1b-d808-4886-a1f4-88b9ab239fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      " 4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.FloatStorage of size 6]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(points)\n",
    "print(points.storage())\n",
    "print(points.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f35a25c-bd96-416b-a206-8bd9605fc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5., 2.],\n",
      "        [1., 3., 1.]])\n",
      " 4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.FloatStorage of size 6]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(points_t)\n",
    "print(points_t.storage())\n",
    "print(points_t.is_contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568def6-303e-4382-aff5-671cd4e8fa18",
   "metadata": {},
   "source": [
    "## 6 - Moving tensors to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1d867-051e-4e6b-b4d0-da7f5446a31a",
   "metadata": {},
   "source": [
    "Tensors have an attribute called `device`. To create a tensor in the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edecfad0-ac9e-44a0-8570-feefc0517fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n",
    "points_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf119cd-8fb8-4559-8df5-328f78ba4d0b",
   "metadata": {},
   "source": [
    "To move an existing tensor to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00cdd305-5140-402d-8d6e-27d67ba10548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = points.to(device='cuda')\n",
    "points_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dad7-27ce-4fe4-8960-1bc47b8ae58c",
   "metadata": {},
   "source": [
    "If there was more than one GPU, the specific choice of GPU can be assigned as well by passing a zero-based integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc0ae007-7c4d-4755-ab23-b9968926f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfccafa-7ed6-4369-8902-9e4d56624e55",
   "metadata": {},
   "source": [
    "All calculations for tensors in the GPU are kept in the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "381dbdf7-74f8-4c11-8421-8c53785f8b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = points_gpu + 4\n",
    "points_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05606e7-66d2-4503-a993-04e1f869f4dd",
   "metadata": {},
   "source": [
    "To move a tensor back to the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fbf11c8-e462-400b-ad9b-42b45cadec98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_cpu = points_gpu.to(device='cpu')\n",
    "points_cpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f81e8-788f-4068-adc6-b86fdc843577",
   "metadata": {},
   "source": [
    "Shorthand methods also exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb448390-b223-41d5-8386-55584214a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.cuda() # Dedfaults to GPU index 0\n",
    "points_gpu = points.cuda(0)\n",
    "points_cpu = points.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0e465-0bff-4694-b272-3b1e8671f38e",
   "metadata": {},
   "source": [
    "## 7 - Tensors and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37be26-0389-4266-9bce-9aac40014799",
   "metadata": {},
   "source": [
    "To convert a PyTorch tensor to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abc8d415-ad3a-488c-a1ea-0fd709c551ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbe38e-5b19-4475-9482-b134272d41eb",
   "metadata": {},
   "source": [
    "Conversely, a NumPy array can be converted to a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0d690ad-3f9b-4a8f-8853-105d124fbd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.from_numpy(points_np)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa5eab-c486-42c1-816c-f9a465d25265",
   "metadata": {},
   "source": [
    "As a side note, the default numeric type in PyTorch is 32-bit floating-point while for NumPy it is 64-bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16511fd-3639-4e7a-948e-cb56cf46af3b",
   "metadata": {},
   "source": [
    "## 8 - Serializing tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026183df-fc01-49ef-8a91-4a21e4f18033",
   "metadata": {},
   "source": [
    "The following code serializes a tensor (PyTorch uses `pickle`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ce7ff06-e08a-4fe9-85cc-c4fef80a3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, './data/ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46668d0f-ec19-4f20-9ffa-472ffb8b6e70",
   "metadata": {},
   "source": [
    "Alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b92713bf-8a16-44b1-bfc2-0188b38b1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ch3/ourpoints.t', 'wb') as f:\n",
    "    torch.save(points, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edc492-954a-4a6e-b876-88d1355fd0fe",
   "metadata": {},
   "source": [
    "To load the tensor back to the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69589e61-15db-414d-9374-0f665081bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.load('./data/ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89288e5-f0d9-4d15-8b05-655d52fc77ec",
   "metadata": {},
   "source": [
    "Alternatively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac819f2d-ee98-4f9f-858a-4b555282296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ch3/ourpoints.t', 'rb') as f:\n",
    "    points = torch.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758aa4f-9d34-426c-8a97-d6e14b5ebf48",
   "metadata": {},
   "source": [
    "Instead of pickle, the HDF5 format can be used through the `h5py` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22cae155-a46f-40c9-a73e-b16c7744cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('./data/ch3/ourpoints.hdf5', 'w')\n",
    "dset = f.create_dataset('coords', data=points.numpy()) # 'coords' is a key into the HDF5 file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d1eca-f45d-4083-be1c-9d22c82c8dc4",
   "metadata": {},
   "source": [
    "To load the HDF5 file into the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c02d859-ed00-4416-adef-2583469cf7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('./data/ch3/ourpoints.hdf5', 'r')\n",
    "dset = f['coords'] # Returns a dataset\n",
    "points = torch.from_numpy(dset[...])\n",
    "f.close()\n",
    "\n",
    "points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
